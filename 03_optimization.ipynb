{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import GPy\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "np.int = int # проблема в устаревшей библиотеке\n",
    "np.bool = bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`\n",
    "pip3 install Gpy\n",
    "pip3 install ipywidgets\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in case of python 3.7 error while installing\n",
    "\n",
    "\n",
    "`git clone https://github.com/SheffieldML/GPy\n",
    "find Gpy -name '*.pyx' -exec cython {} \\;\n",
    "pip3 install Gpy/`\n",
    "\n",
    "https://github.com/SheffieldML/GPy/issues/649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, widgets, fixed\n",
    "try:\n",
    "    from ipywidgets import Layout\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## функции для оптимизации и отображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_expected_improvement(mean_values, variance_values, opt_value):\n",
    "    estimated_values = mean_values.ravel()\n",
    "    eps = 0.05 / len(estimated_values)\n",
    "\n",
    "    delta = (opt_value - estimated_values - eps).ravel()\n",
    "\n",
    "    estimated_errors = (variance_values ** 0.5).ravel()\n",
    "\n",
    "    non_zero_error_inds = np.where(estimated_errors > 1e-6)[0]\n",
    "    Z = np.zeros(len(delta))\n",
    "    Z[non_zero_error_inds] = delta[non_zero_error_inds] / estimated_errors[non_zero_error_inds]\n",
    "    log_EI = np.log(estimated_errors) + norm.logpdf(Z) + np.log(1 + Z * np.exp(norm.logcdf(Z) - norm.logpdf(Z)))\n",
    "    return log_EI\n",
    "\n",
    "\n",
    "def get_new_point(model, lb, ub, data=None, multistart=50, random_state=None):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        model - GP model of the objective function\n",
    "        lb, ub - array-like, lower and upper bounds of x\n",
    "        data - tuple(x_train, y_train)\n",
    "        multistart - number of multistart runs\n",
    "        random_state - np.random.RandomState\n",
    "    Returns\n",
    "        tuple - argmin of the objective function and min value of the objective\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState()\n",
    "\n",
    "    lb = np.array(lb).reshape(1, -1)\n",
    "    ub = np.array(ub).reshape(1, -1)\n",
    "\n",
    "    # 1. Generate inital X points (number of points == multistart) in [lb, ub]\n",
    "\n",
    "    x_random = random_state.uniform(size=(multistart, np.array(lb).ravel().shape[0]))\n",
    "    x_random *= ub - lb\n",
    "    x_random += lb\n",
    "\n",
    "    def objective(x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(1, -1)\n",
    "        mean_values, variance = model.predict(x)\n",
    "        std_values = np.sqrt(variance)\n",
    "        return -log_expected_improvement(mean_values, std_values, data[1].min())\n",
    "\n",
    "    criterion_value = objective(x_random)\n",
    "\n",
    "    # 2. From each points from x_random run L-BFGS optimization algorithm,\n",
    "    #    choose the best result and return it\n",
    "    #    Use function minimize: minimize(objective, x_init, method='L-BFGS-B',\n",
    "    #                                    bounds=np.vstack((lb, ub)).T)\n",
    "    #    it returns object with fields 'fun' - optimum function value, 'x' - argmin.\n",
    "\n",
    "    best_result = None\n",
    "    best_value = np.inf\n",
    "\n",
    "    for x_init in x_random:\n",
    "        optimization_result = minimize(objective, x_init, method='L-BFGS-B', bounds=np.vstack((lb, ub)).T)\n",
    "\n",
    "        if optimization_result.fun < best_value:\n",
    "            best_result = optimization_result\n",
    "            best_value = best_result.fun[0]\n",
    "    return best_result.x, best_result.fun\n",
    "\n",
    "\n",
    "def get_model_values(model, x, y_train):\n",
    "    prediction, variance = model.predict(x)\n",
    "    std = np.sqrt(variance).ravel()\n",
    "\n",
    "    log_EI = np.exp(log_expected_improvement(prediction, std, y_train.min()))\n",
    "\n",
    "    values = [prediction, log_EI, std]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _plot_2D(x_grid, values, x_new, x_train, need_log=True):\n",
    "    \"\"\"subprogram for plotting 2D values\"\"\"\n",
    "    # узнаём длину ребра = корень из \"площади\"\n",
    "    grid_size = int(np.sqrt(len(x_grid[:, 0])))\n",
    "    # строим grid в нужной нотации (с продольной на квадратную)\n",
    "    tX_grid = x_grid[:, 0].reshape(grid_size, grid_size)\n",
    "    tY_grid = x_grid[:, 1].reshape(grid_size, grid_size)\n",
    "    # меняем нотацию матрицы (-//-)\n",
    "    Y_matrix = values.reshape(grid_size, grid_size)\n",
    "    # поскольку мы работаем с маленькими значениями параметров, переведём их в \"научный\" формат\n",
    "    plt.ticklabel_format(axis='y', style='sci', scilimits=(0, 0))\n",
    "    plt.ticklabel_format(axis='x', style='sci', scilimits=(0, 0))\n",
    "    # строим само распределение. В логорифмическом масштабе или без оного\n",
    "    if need_log:\n",
    "        plt.pcolormesh(tX_grid, tY_grid, Y_matrix, norm=LogNorm())\n",
    "    else:\n",
    "        plt.pcolormesh(tX_grid, tY_grid, Y_matrix)\n",
    "    plt.colorbar()\n",
    "    # обозначим, где находится \"0\" -- без добавок\n",
    "    plt.axhline(0, color=\"w\", linewidth=0.8, linestyle=\":\")\n",
    "    plt.axvline(0, color=\"w\", linewidth=0.8, linestyle=\":\")\n",
    "\n",
    "    # обозначим точки, где уже знаем функцию\n",
    "    plt.scatter(x_train[:, 0], x_train[:, 1], c='r', s=20)\n",
    "    # и если уже решили, где будем искать следующее значение -- обозначим место тоже\n",
    "    if x_new is not None:\n",
    "        plt.axvline(x_new[0], color=\"green\")\n",
    "        plt.axhline(x_new[1], color=\"green\")\n",
    "\n",
    "\n",
    "def _plot_1D(x_grid, values, x_new, x_train, y_train, train_display, need_log=True):\n",
    "    \"\"\"subprogram for plotting 1D values\"\"\"\n",
    "    # поскольку мы работаем с маленькими значениями параметров, переведём их в \"научный\" формат\n",
    "    plt.ticklabel_format(axis='x', style='sci', scilimits=(0, 0))\n",
    "    # отображаем тренировочный сет. Для y_predicted и EI отображение отличается, поэтому выносим его\n",
    "    # в отдельную (так же передаваемую) функцию\n",
    "    train_display(x_train, y_train)\n",
    "    # отображем распределение\n",
    "    plt.plot(x_grid, values.ravel(), '-k', linewidth=2)\n",
    "    # показываем, где 0\n",
    "    plt.axvline(0, linewidth=0.8, linestyle=\":\")\n",
    "    # если хотим логорифмический масштаб,\n",
    "    if need_log:\n",
    "        plt.yscale(\"log\")\n",
    "    if x_new is not None:\n",
    "        plt.axvline(x_new, color=\"green\")\n",
    "\n",
    "\n",
    "def plot_model_EI(x_train, y_train, x_grid, y_predict, std_, log_EI=None, x_new=None):\n",
    "    # смотрим размерность пространства (1D или 2D)\n",
    "    is_dim1 = x_train.shape[1] == 1\n",
    "    is_dim2 = x_train.shape[1] == 2\n",
    "    # один или два графика? Если два, фигура побольше и подграфики делаем\n",
    "    if log_EI is not None:\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        plt.subplot(121)\n",
    "    else:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # рисуем предсказания модели\n",
    "    plt.title(\"y predict\")\n",
    "    # для 1D\n",
    "    if is_dim1:\n",
    "        _plot_1D(\n",
    "            x_grid, y_predict, x_new, x_train, y_train,\n",
    "            # тренировочный сет обозначем маркерами\n",
    "            train_display=lambda xs, ys: plt.plot(xs, ys, 'or', markersize=8),\n",
    "            need_log=False\n",
    "        )\n",
    "        # плюсом добавим, насколько мы не уверены в результате?\n",
    "        prediction = y_predict.ravel()\n",
    "        std = std_.ravel()\n",
    "        plt.fill_between(x_grid.ravel(), prediction - 2 * std, prediction + 2 * std, alpha=0.3)\n",
    "    # для 2D\n",
    "    if is_dim2:\n",
    "        _plot_2D(x_grid, y_predict, x_new, x_train, need_log=False)\n",
    "\n",
    "    # рисуем log EI\n",
    "    if log_EI is not None:\n",
    "        plt.subplot(122)\n",
    "        plt.title(\"log EI\")\n",
    "        # для 1D\n",
    "        if is_dim1:\n",
    "            _plot_1D(\n",
    "                x_grid, log_EI, x_new, x_train, y_train=None,\n",
    "                # тренировочный сет обозначаем вертикальными линиями\n",
    "                train_display=lambda xs, _: np.vectorize(\n",
    "                    lambda x: plt.axvline(x, color=\"r\", linewidth=0.8, linestyle=\":\")\n",
    "                )(xs),\n",
    "                need_log=False\n",
    "            )\n",
    "        # для 2D\n",
    "        if is_dim2:\n",
    "            _plot_2D(x_grid, log_EI, x_new, x_train, need_log=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracul(x):\n",
    "    return float(input(\"введите значение в точке {}: \".format(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## оптимизация для одного параметра"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### границы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds = [0]\n",
    "upper_bounds = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### тренировочный набор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([0, 0.2, 0.8, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(значение функции возьмите из файла `04_function`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([oracul(x) for x in x_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### посмотрим, что имеем в начале"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(1)\n",
    "model = GPy.models.GPRegression(x_train, y_train, kernel)\n",
    "model.Gaussian_noise.variance = 0.00001\n",
    "model.Gaussian_noise.variance.fix()\n",
    "model.optimize_restarts(verbose=False, num_restarts=10)\n",
    "\n",
    "grid_size = 50\n",
    "x_grid = np.linspace(lower_bounds[0], upper_bounds[0], grid_size).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict, log_EI, std = get_model_values(model, x_grid, y_train)\n",
    "plot_model_EI(x_train, y_train, x_grid, y_predict, std, log_EI, x_new=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### оптимизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    kernel = GPy.kern.RBF(1)\n",
    "    model = GPy.models.GPRegression(x_train, y_train, kernel)\n",
    "    model.Gaussian_noise.variance = 0.00001\n",
    "    model.Gaussian_noise.variance.fix()\n",
    "    model.optimize_restarts(verbose=False, num_restarts=10)\n",
    "\n",
    "    grid_size = 50\n",
    "    x_grid = np.linspace(lower_bounds[0], upper_bounds[0], grid_size).reshape(-1,1)\n",
    "    x_new, criterion_value = get_new_point(\n",
    "        model, data=(x_train, y_train), lb=lower_bounds, ub=upper_bounds\n",
    "    )\n",
    "    \n",
    "    y_predict, log_EI, std = get_model_values(model, x_grid, y_train)\n",
    "    plot_model_EI(x_train, y_train, x_grid, y_predict, std, log_EI, x_new)\n",
    "    x_new = x_new.reshape(1, -1)\n",
    "    new_value = np.array([oracul(x_new.ravel()[0])]).reshape(1, -1)\n",
    "    print(x_new, \"-->\", new_value)\n",
    "    x_train = np.vstack([x_train, x_new])\n",
    "    y_train = np.vstack([y_train, new_value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### и в итоге получаем:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(1)\n",
    "model = GPy.models.GPRegression(x_train, y_train, kernel)\n",
    "model.Gaussian_noise.variance = 0.00001\n",
    "model.Gaussian_noise.variance.fix()\n",
    "model.optimize_restarts(verbose=False, num_restarts=10)\n",
    "\n",
    "grid_size = 50\n",
    "x_grid = np.linspace(lower_bounds[0], upper_bounds[0], grid_size).reshape(-1,1)\n",
    "y_predict, log_EI, std = get_model_values(model, x_grid, y_train)\n",
    "plot_model_EI(x_train, y_train, x_grid, y_predict, std, log_EI=None, x_new=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## попробуем для 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds = [0, -1]\n",
    "upper_bounds = [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oracul2D(X):\n",
    "    r = np.linalg.norm(X)\n",
    "    return r**5 + r + np.sin(4*np.pi * r) - 5*(1/np.sqrt((X[0]-1)**2+1)) - 3*np.abs(X[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([\n",
    "    [0, 0],\n",
    "    [1, 1],\n",
    "    [0.8, 0.2],\n",
    "    [0.3, 0.75], \n",
    "    [1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([oracul2D(x) for x in x_train]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_size = 50\n",
    "xy_grid = np.meshgrid(\n",
    "    np.linspace(lower_bounds[0], upper_bounds[0], grid_size), \n",
    "    np.linspace(lower_bounds[1], upper_bounds[1], grid_size)\n",
    ")\n",
    "x_grid = np.hstack((xy_grid[0].reshape(-1, 1), xy_grid[1].reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = GPy.kern.RBF(2, ARD=False)  # ARD=False значит, что характерная длина по x и y совпадают\n",
    "model = GPy.models.GPRegression(x_train, y_train, kernel)\n",
    "model.Gaussian_noise.variance = 0.00001\n",
    "model.Gaussian_noise.variance.fix()\n",
    "model.optimize_restarts(verbose=False, num_restarts=10);\n",
    "\n",
    "y_predict, log_EI, std = get_model_values(model, x_grid, y_train)\n",
    "plot_model_EI(x_train, y_train, x_grid, y_predict, std, log_EI, x_new=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    kernel = GPy.kern.RBF(2, ARD=False)\n",
    "    model = GPy.models.GPRegression(x_train, y_train, kernel)\n",
    "    model.Gaussian_noise.variance = 0.00001\n",
    "    model.Gaussian_noise.variance.fix()\n",
    "    model.optimize_restarts(verbose=False, num_restarts=10)\n",
    "\n",
    "    x_new, criterion_value = get_new_point(\n",
    "        model, data=(x_train, y_train), lb=lower_bounds, ub=upper_bounds\n",
    "    )\n",
    "    \n",
    "    y_predict, log_EI, std = get_model_values(model, x_grid, y_train)\n",
    "    plot_model_EI(x_train, y_train, x_grid, y_predict, std, log_EI, x_new)\n",
    "    x_new = x_new.reshape(1, -1)\n",
    "    new_value = np.array([oracul2D(x_new.ravel())]).reshape(1, -1)\n",
    "    print(x_new, \"-->\", new_value)\n",
    "    x_train = np.vstack([x_train, x_new])\n",
    "    y_train = np.vstack([y_train, new_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict, log_EI, std = get_model_values(model, x_grid, y_train)\n",
    "plot_model_EI(x_train, y_train, x_grid, y_predict, std, log_EI=None, x_new=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## а как же эта функция выглядит на самом деле?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.array([oracul2D(x) for x in x_grid]).reshape(-1,1)\n",
    "plot_model_EI(x_train, y_train, x_grid, y_predict, std, log_EI=None, x_new=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Где у неё минимум?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict.min(), x_grid[y_predict.argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### как видите, минимум в нижней половине. Мы её вообще не смотрели! \n",
    "\n",
    "## Вывод -- даже с этим алгоритмом надо быть аккуратным и не полностью полагаться на его результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
